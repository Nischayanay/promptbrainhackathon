# ðŸ§  PromptBrain Backend Rulebook (Vanilla Logic)

1. Core Philosophy

Every raw prompt = incomplete instruction.

Backend logic = fill the gaps systematically using rules + frameworks.

Output must be CRISP: Clarity, Relevance, Intent alignment, Specificity, Precision.

No randomness â†’ Always structured, predictable improvement.

2. Enhancement Pipeline
Raw Prompt â†’ Context Expansion â†’ Domain Detection â†’ Framework Mapping â†’ Enhancement â†’ CRISP Validation â†’ Final Output

3. Context Expansion

Whenever input is vague or underspecified, automatically enrich with:

Role: Who is speaking? (teacher, marketer, coder, strategist, explainer)

Task: Whatâ€™s the user really asking for? (summary, code, pitch, essay, plan)

Audience: Who is this meant for? (students, customers, devs, investors)

Constraints: Tone, format, length, perspective.

Examples: Add one illustrative example to ground the AI.

4. Domain Detection

Classifier routes prompt into buckets:

Research / Knowledge â†’ STAR, CRISP, SERP

Marketing / Persuasion â†’ AIDA, PAS, FAB

Strategy / Planning â†’ OSCAR, RASCE

Explainer / Education â†’ IEEI, STAR-simplified

Creative Ideation â†’ SCAMPER, lateral patterns

Coding / Technical â†’ RTF, stepwise RASCE

5. Framework Mapping

Each domain enforces a structure:

Marketing â†’ AIDA (hook â†’ build interest â†’ create desire â†’ call-to-action)

Research â†’ STAR (Situation â†’ Task â†’ Action â†’ Result)

Strategy â†’ RASCE (Role â†’ Action â†’ Steps â†’ Constraints â†’ Evaluation)

Explainer â†’ IEEI (Involve â†’ Explain â†’ Example â†’ Involve again)

Coding â†’ RTF (Role â†’ Task â†’ Format, with explicit syntax rules)

Creative â†’ SCAMPER (Substitute, Combine, Adapt, Modify, Put to use, Eliminate, Reverse)

6. Enhancement Rules

If missing context â†’ Insert defaults based on domain.

If prompt is too broad â†’ Narrow scope (timeframe, audience, purpose).

If prompt is too short â†’ Expand with task clarity + role + output format.

If prompt is too long/unfocused â†’ Split into modular sub-prompts.

Always add actionability â†’ â€œDo this step-by-stepâ€ or â€œProduce X in Y format.â€

7. CRISP Validation Layer

Before sending back, every enhanced prompt must pass:

Clarity â†’ No vague phrases (â€œsomething,â€ â€œgood,â€ â€œbetterâ€).

Relevance â†’ Directly tied to userâ€™s goal.

Intent alignment â†’ Matches task type (ad copy â‰  essay tone).

Specificity â†’ Concrete details (audience, style, constraints).

Precision â†’ Output format enforced (bullets, JSON, table, etc.).

8. Output Standard

Two Formats Returned:

Natural English prompt (human-friendly).

JSON prompt object (machine-readable, reusable).

Example JSON:

{
  "role": "Marketing strategist",
  "task": "Write ad copy for coffee brand",
  "audience": "Urban professionals 25â€“35",
  "framework": "AIDA",
  "format": "3 variations, each under 50 words",
  "constraints": "Casual, witty tone",
  "example": "Start with a hook about 'Monday mornings'"
}

9. Golden Rules (Backend)

Never return â€œas isâ€ raw text â†’ always structured.

Every enhancement adds context + structure + clarity.

The same raw input â†’ always produces the same structured upgrade.

User can trust the machine: Predictable > Creative guessing.
